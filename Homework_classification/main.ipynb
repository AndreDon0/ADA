{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Classification task](https://www.kaggle.com/competitions/star-type-classification)\n",
    "\n",
    "- **Vmag** - Визуальная видимая величина звезды\n",
    "- **Plx** - Расстояние между звездой и Землей (параллакс)\n",
    "- **e_Plx** - Стандартная ошибка параллакса (подсказка: если значение очень велико - это плохо, скорее всего такие объекты нужно отбросить)\n",
    "- **B-V** - Индекс цвета. (Горячая звезда имеет показатель цвета B-V, близкий к 0 или отрицательный, тогда как холодная звезда имеет показатель цвета B-V, близкий к 2).\n",
    "- **SpType** - Спектральный тип звезды по классификации МК\n",
    "- **Amag** - Абсолютная величина звезды (Absolute Magnitude of the Star)\n",
    "- **TargetClass** - Целевая переменная (Является ли звезда карликом (0) или гигантом (1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train_star.csv\")\n",
    "test = pd.read_csv(\"test_star.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(columns=\"SpType\", axis=1)\n",
    "test = test.drop(columns=\"SpType\", axis=1)\n",
    "\n",
    "train[\"TargetClass\"] = (train[\"TargetClass\"] == \"Giant\").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=\"TargetClass\", axis=1)\n",
    "y_train = train[\"TargetClass\"]\n",
    "\n",
    "X_test = test.copy()\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_test = log_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y_test).rename(columns={0: \"TargetClass\"}).reset_index().to_csv(\"prediction.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deepseek code\n",
    "\n",
    "У меня есть датасет без пропусков звезд с следующими параметрами:\n",
    "- **Vmag** - Визуальная видимая величина звезды\n",
    "- **Plx** - Расстояние между звездой и Землей (параллакс)\n",
    "- **e_Plx** - Стандартная ошибка параллакса (подсказка: если значение очень велико - это плохо, скорее всего такие объекты нужно отбросить)\n",
    "- **B-V** - Индекс цвета. (Горячая звезда имеет показатель цвета B-V, близкий к 0 или отрицательный, тогда как холодная звезда имеет показатель цвета B-V, близкий к 2).\n",
    "- **SpType** - Спектральный тип звезды по классификации МК\n",
    "- **Amag** - Абсолютная величина звезды (Absolute Magnitude of the Star)\n",
    "- **TargetClass** - Целевая переменная (Является ли звезда карликом (0) или гигантом (1))\n",
    "\n",
    "Мне нужно предсказать при помощи классификации TargetClass.\n",
    "Команда `train[\"TargetClass\"].value_counts()` выдает:\n",
    "```\n",
    "TargetClass\n",
    "Giant    15793\n",
    "Dwarf     4939\n",
    "```\n",
    "А `train[\"SpType\"].unique()`:\n",
    "```\n",
    "array(['G5/G6V', 'M1V:', 'F3V', ..., 'B6Vwp...', 'G6:V:+...', 'K1V(p)'],\n",
    "      dtype=object)\n",
    "```\n",
    "Длинны 1600.\n",
    "Я ожидаю от тебя нейронную сеть наиболее подходящую для этой задачи, которая на другой часть датасета выдаст ответ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 20732 entries, 0 to 20731\n",
      "Series name: TargetClass\n",
      "Non-Null Count  Dtype\n",
      "--------------  -----\n",
      "20732 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 162.1 KB\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andredon/projects/ADA/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5189 - auc_10: 0.5021 - loss: 0.8115 - val_accuracy: 0.2453 - val_auc_10: 0.4704 - val_loss: 0.7592\n",
      "Epoch 2/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3599 - auc_10: 0.5133 - loss: 0.7985 - val_accuracy: 0.2556 - val_auc_10: 0.4581 - val_loss: 0.7426\n",
      "Epoch 3/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3985 - auc_10: 0.5165 - loss: 0.7841 - val_accuracy: 0.2622 - val_auc_10: 0.4689 - val_loss: 0.7400\n",
      "Epoch 4/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3850 - auc_10: 0.5188 - loss: 0.7845 - val_accuracy: 0.2575 - val_auc_10: 0.4762 - val_loss: 0.7455\n",
      "Epoch 5/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3578 - auc_10: 0.5165 - loss: 0.7967 - val_accuracy: 0.2594 - val_auc_10: 0.4792 - val_loss: 0.7419\n",
      "Epoch 6/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3659 - auc_10: 0.5172 - loss: 0.7915 - val_accuracy: 0.2659 - val_auc_10: 0.4780 - val_loss: 0.7342\n",
      "Epoch 7/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3611 - auc_10: 0.5316 - loss: 0.7833 - val_accuracy: 0.2650 - val_auc_10: 0.4813 - val_loss: 0.7335\n",
      "Epoch 8/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3525 - auc_10: 0.5208 - loss: 0.7872 - val_accuracy: 0.2706 - val_auc_10: 0.4803 - val_loss: 0.7308\n",
      "Epoch 9/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3631 - auc_10: 0.5183 - loss: 0.7857 - val_accuracy: 0.2809 - val_auc_10: 0.4843 - val_loss: 0.7283\n",
      "Epoch 10/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3602 - auc_10: 0.5208 - loss: 0.7938 - val_accuracy: 0.2715 - val_auc_10: 0.4837 - val_loss: 0.7329\n",
      "Epoch 11/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3438 - auc_10: 0.5271 - loss: 0.7880 - val_accuracy: 0.2603 - val_auc_10: 0.4879 - val_loss: 0.7325\n",
      "Epoch 12/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3477 - auc_10: 0.5338 - loss: 0.7864 - val_accuracy: 0.2734 - val_auc_10: 0.4922 - val_loss: 0.7293\n",
      "Epoch 13/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3380 - auc_10: 0.5439 - loss: 0.7963 - val_accuracy: 0.2584 - val_auc_10: 0.4983 - val_loss: 0.7322\n",
      "Epoch 14/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3365 - auc_10: 0.5344 - loss: 0.7801 - val_accuracy: 0.2959 - val_auc_10: 0.4870 - val_loss: 0.7216\n",
      "Epoch 15/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3502 - auc_10: 0.5243 - loss: 0.7934 - val_accuracy: 0.2706 - val_auc_10: 0.4869 - val_loss: 0.7322\n",
      "Epoch 16/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3314 - auc_10: 0.5417 - loss: 0.7919 - val_accuracy: 0.2669 - val_auc_10: 0.4885 - val_loss: 0.7309\n",
      "Epoch 17/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3296 - auc_10: 0.5233 - loss: 0.7910 - val_accuracy: 0.2865 - val_auc_10: 0.4885 - val_loss: 0.7272\n",
      "Epoch 18/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3457 - auc_10: 0.5457 - loss: 0.7808 - val_accuracy: 0.2846 - val_auc_10: 0.4903 - val_loss: 0.7304\n",
      "Epoch 19/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3372 - auc_10: 0.5198 - loss: 0.7903 - val_accuracy: 0.2903 - val_auc_10: 0.4896 - val_loss: 0.7286\n",
      "\u001b[1m589/589\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167us/step\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, layers, callbacks, optimizers\n",
    "\n",
    "# Функции для обработки SpType\n",
    "def parse_spectral_class(sptype):\n",
    "    match = re.match(r'^([OBAFGKM])([^/]*)', sptype)\n",
    "    return match.group(1) if match else 'Unknown'\n",
    "\n",
    "def parse_subclass(sptype):\n",
    "    match = re.search(r'(\\d+\\.?\\d*)', sptype)\n",
    "    return float(match.group(1)) if match else 0.0\n",
    "\n",
    "def parse_luminosity_class(sptype):\n",
    "    match = re.search(r'(II{1,2}|I{1,4}|IV|V)\\b', sptype)\n",
    "    return match.group(1) if match else 'V' if 'V' in sptype else 'Unknown'\n",
    "\n",
    "# Предобработка данных\n",
    "class DataPreprocessor:\n",
    "    def __init__(self):\n",
    "        self.scaler = None\n",
    "        self.spectral_classes = ['O','B','A','F','G','K','M','Unknown']\n",
    "        self.luminosity_classes = ['V','IV','III','II','I','Unknown']\n",
    "    \n",
    "    def fit_transform(self, df, is_train=True):\n",
    "        df = df.copy()\n",
    "        # Извлечение признаков\n",
    "        df['spectral_class'] = df['SpType'].apply(parse_spectral_class)\n",
    "        df['subclass'] = df['SpType'].apply(parse_subclass)\n",
    "        df['luminosity_class'] = df['SpType'].apply(parse_luminosity_class)\n",
    "        \n",
    "        # Фильтрация только для трейна\n",
    "        if is_train:\n",
    "            df = df[(df['Plx'] > 0) & (df['e_Plx']/df['Plx'] < 0.1)]\n",
    "        \n",
    "        # Кодирование категориальных признаков\n",
    "        df['spectral_class'] = pd.Categorical(df['spectral_class'], categories=self.spectral_classes)\n",
    "        spectral_dummies = pd.get_dummies(df['spectral_class'], prefix='spec')\n",
    "        \n",
    "        df['luminosity_class'] = pd.Categorical(df['luminosity_class'], categories=self.luminosity_classes)\n",
    "        luminosity_dummies = pd.get_dummies(df['luminosity_class'], prefix='lum')\n",
    "        \n",
    "        # Числовые признаки\n",
    "        df['Plx_over_ePlx'] = df['Plx'] / df['e_Plx'].replace(0, np.nan)\n",
    "        df['Plx_over_ePlx'] = df['Plx_over_ePlx'].fillna(0).replace([np.inf, -np.inf], 0)\n",
    "        \n",
    "        numerical = ['Vmag','Plx','e_Plx','B-V','Amag','subclass','Plx_over_ePlx']\n",
    "        \n",
    "        # Масштабирование\n",
    "        if is_train:\n",
    "            self.scaler = StandardScaler()\n",
    "            df[numerical] = self.scaler.fit_transform(df[numerical])\n",
    "        else:\n",
    "            df[numerical] = self.scaler.transform(df[numerical])\n",
    "            \n",
    "        return pd.concat([df[numerical], spectral_dummies, luminosity_dummies], axis=1)\n",
    "\n",
    "# Загрузка данных\n",
    "train = pd.read_csv(\"train_star.csv\")\n",
    "test = pd.read_csv(\"test_star.csv\")\n",
    "\n",
    "# Предобработка\n",
    "preprocessor = DataPreprocessor()\n",
    "X_train = preprocessor.fit_transform(train.drop(columns=['TargetClass']), is_train=True)\n",
    "y_train = (train[\"TargetClass\"] == \"Giant\").astype(int)\n",
    "X_test = preprocessor.fit_transform(test, is_train=False)\n",
    "\n",
    "# Построение модели\n",
    "model = Sequential([\n",
    "    layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.AUC()]\n",
    ")\n",
    "\n",
    "# Балансировка классов\n",
    "class_weight = {0: 2.5, 1: 0.7}\n",
    "y_train.info()\n",
    "\n",
    "# Обучение\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=100,\n",
    "    batch_size=256,\n",
    "    validation_split=0.2,\n",
    "    class_weight=class_weight,\n",
    "    callbacks=[callbacks.EarlyStopping(patience=5, restore_best_weights=True)]\n",
    ")\n",
    "\n",
    "# Предсказание и сохранение\n",
    "predictions = model.predict(X_test)\n",
    "result = pd.DataFrame({\n",
    "    'TargetClass': (predictions.squeeze() >= 0.5).astype(int)\n",
    "})\n",
    "pd.DataFrame(result).rename(columns={0: \"TargetClass\"}).reset_index().to_csv(\"predictions.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
